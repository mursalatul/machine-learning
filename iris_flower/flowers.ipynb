{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "OrhiwlVlCpE2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df_species = train_df.pop('species')\n",
        "test_df_species = test_df.pop('species')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sLMuTOEDDxM",
        "outputId": "cfaed0c3-2af2-4f3e-c333-21c772cc3e5f"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      2\n",
              "1      1\n",
              "2      1\n",
              "3      2\n",
              "4      2\n",
              "      ..\n",
              "135    2\n",
              "136    1\n",
              "137    1\n",
              "138    1\n",
              "139    1\n",
              "Name: species, Length: 140, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns = []\n",
        "# for feature_name in train_df.keys():\n",
        "for feature_name in ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))"
      ],
      "metadata": {
        "id": "fP_LAWCSKbDM"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_input_fn(data, label, epoch=100, shuffle=True, batch_size=232):\n",
        "  def inp():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(data), label))\n",
        "    if shuffle:\n",
        "      dataset = dataset.shuffle(1000)\n",
        "    dataset = dataset.batch(batch_size).repeat(epoch)\n",
        "    return dataset\n",
        "  return inp\n",
        "\n",
        "train_fn = make_input_fn(train_df, train_df_species)\n",
        "test_fn = make_input_fn(test_df, test_df_species, epoch=1, shuffle=False)"
      ],
      "metadata": {
        "id": "vshi2JGARlUx"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    hidden_units=[30, 10],\n",
        "    n_classes=3\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "    train_fn,\n",
        "    steps=5000\n",
        ")\n",
        "ac1 = classifier.evaluate(test_fn)\n",
        "print(\"DNN accuracy:\", ac1['accuracy'])\n",
        "\n",
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns, n_classes=3)\n",
        "linear_est.train(train_fn)\n",
        "\n",
        "ac2 = linear_est.evaluate(test_fn)\n",
        "print(\"Linear accuracy:\", ac2['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7lPkyu2SpVw",
        "outputId": "8c8ce699-92ae-4417-868b-16ee9697c712"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp81d62weg\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp1w9c0w6o\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNN accuracy: 0.3\n",
            "Linear accuracy: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.evaluate(test_fn)"
      ],
      "metadata": {
        "id": "CweiyNkU0ZzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_fn_no_lable(data, batch_size=256):\n",
        "  def inpp():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data)))\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds\n",
        "  return inpp\n",
        "\n",
        "for _ in range(10):\n",
        "  predict = {}\n",
        "  for feature in train_df.keys():\n",
        "    valid = True\n",
        "    while valid:\n",
        "      val = input(feature + \": \")\n",
        "      valid =  val.isdigit()\n",
        "    predict[feature] = [float(val)]\n",
        "\n",
        "\n",
        "  get_predict_fn = input_fn_no_lable(predict)\n",
        "\n",
        "  prediction1 = classifier.predict(get_predict_fn)\n",
        "  prediction2 = linear_est.predict(get_predict_fn)\n",
        "  l = list(prediction1)\n",
        "  l2 = list(prediction2)\n",
        "  cls = {\n",
        "      '0': 'Setosa',\n",
        "      '1': 'Versicolor',\n",
        "      '2': 'Virginica'\n",
        "  }\n",
        "  print(\"Prediction 1(DNN):\",cls[str(l[0]['class_ids'][0])], max(l[0]['probabilities']))\n",
        "  print(\"Prediction 2(Lin):\",cls[str(l2[0]['class_ids'][0])], max(l2[0]['probabilities']))\n"
      ],
      "metadata": {
        "id": "lZSNh_Eov0tQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}